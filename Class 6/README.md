# Lab 6: The Architecture of Bias

## Overview
This lab investigates how bias is introduced at the level of the **Data Generating Process (DGP)** and sampling design, before any model is trained. Using simulations and real-world data, the project demonstrates how sampling error, covariate shift, and engineering failures can invalidate statistical inference and machine learning results.

The lab emphasizes forensic analysis of data pipelines rather than post-hoc model tuning.

---

## Objectives
- Analyze how sampling strategies affect variance and representativeness
- Identify and correct Sampling Bias, Covariate Shift, and Sample Ratio Mismatch (SRM)
- Connect applied experiments to statistical theory and causal inference

---

## Tech Stack
- Python  
- pandas, numpy  
- scipy (Chi-Square tests)  
- scikit-learn  

---

## Methodology

### 1. Simple Random Sampling (SRS)
- Manually simulated Simple Random Sampling on the Titanic dataset
- Demonstrated high variance and unstable class distributions under naive random sampling
- Showed that randomness alone does not guarantee representativeness

---

### 2. Stratified Sampling
- Implemented Stratified Sampling using scikit-learn
- Preserved class distributions across splits
- Eliminated covariate shift in the target variable

---

### 3. Sample Ratio Mismatch (SRM) Forensic Audit
- Conducted Chi-Square tests comparing observed vs. expected group assignments in A/B tests
- Detected statistically significant deviations caused by simulated engineering failures

---

## Theoretical Discussion

### Survivorship Bias in Unicorn Startup Analysis
Analyzing only successful unicorn startups (e.g., those featured on TechCrunch) conditions the dataset on survival. This introduces **Survivorship Bias** by excluding startups that failed or never gained visibility, despite being generated by the same underlying economic process.

As a result, estimated relationships (such as funding efficiency or growth rates) are systematically biased upward, and failure mechanisms become invisible.

---

### Ghost Data Required for Heckman Correction
To correct this bias using a Heckman Selection Model, **ghost data** about non-selected observations is required:

- Startups that failed, stagnated, or never achieved unicorn status
- Startups that never received media coverage

Additionally, variables affecting **selection but not outcomes** (exclusion restrictions) are needed, such as:
- Media exposure likelihood
- Founder network proximity to journalists
- Accelerator demo-day participation
- Ecosystem or geographic visibility

These variables allow the selection process to be modeled explicitly, correcting for biased inference.

---

## Key Takeaway
Bias is architectural, not accidental. If the data pipeline is flawed, no amount of modeling sophistication can recover unbiased conclusions. Statistical integrity begins at sampling, assignment, and measurementâ€”not at model training.
